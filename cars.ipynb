{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from flask import Flask, request, jsonify\n",
    "import os\n",
    "import numpy as np\n",
    "import uuid\n",
    "\n",
    "app = Flask(__name__) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "Expected = {\n",
    "    \"cylinders\": {\"min\":3, \"max\": 8},\n",
    "    \"displacement\": {\"min\":68.0, \"max\": 455.0},\n",
    "    \"horsepower\": {\"min\":46.0, \"max\": 230.0},\n",
    "    \"weight\": {\"min\":1613, \"max\": 5140},\n",
    "    \"acceleration\": {\"min\":8.0, \"max\": 24.8},\n",
    "    \"model year\": {\"min\":70, \"max\": 82},\n",
    "    \"origin\": {\"min\":1, \"max\": 3}\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "model = load_model('Models/mpg_model.h5')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-27 18:10:40.249567: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX\n",
      "2021-09-27 18:10:40.262409: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3501000000 Hz\n",
      "2021-09-27 18:10:40.263910: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fffccc324b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-09-27 18:10:40.263989: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-09-27 18:10:40.264349: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 25)                200       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 471\n",
      "Trainable params: 471\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "@app.route('/api', methods=['POST'])\n",
    "def mpg_prediction():\n",
    "    content = request.json\n",
    "    errors = []\n",
    "    for key in content:\n",
    "        if key in Expected:\n",
    "            expected_min = Expected[key]['min']\n",
    "            expected_max = Expected[key]['max']\n",
    "            value = content[key]\n",
    "            if value < expected_min or value > expected_max:\n",
    "                errors.append(f'Out of bounds: {key}, has value of: {value}, but it should be between {expected_min} and {expected_max}')\n",
    "        else:\n",
    "            errors.append(f'Unexpected field: {key}.')\n",
    "\n",
    "    for key in Expected:\n",
    "        if key not in content:\n",
    "            errors.append(f'Missing value: {key}')\n",
    "    if len(errors) < 1:\n",
    "        x = np.zeros((1,7))\n",
    "\n",
    "        x[0,0] = content['cylinders']\n",
    "        x[0,1] = content['displacement']\n",
    "        x[0,2] = content['horsepower']\n",
    "        x[0,3] = content['weight']\n",
    "        x[0,4] = content['acceleration']\n",
    "        x[0,5] = content['model year']\n",
    "        x[0,6] = content['origin']\n",
    "\n",
    "        prediction = model.predict(x)\n",
    "        mpg = float(prediction[0])\n",
    "        response = { 'id': str(uuid.uuid4()), 'mpg': mpg, 'errors': errors}    \n",
    "    else:\n",
    "        response = {'id': str(uuid.uuid4()), 'errors': errors}\n",
    "    \n",
    "    return jsonify(response)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('tensorflow': conda)"
  },
  "interpreter": {
   "hash": "31d94936c292a89639dcc941b94dff496b473e8862f648d3cf1fe088e3ebc300"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}